{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8567382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from threading import Thread\n",
    "from threading import RLock\n",
    "ocr_model = PaddleOCR(lang='en',use_angle_cls=False,show_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bfbbb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(img,orig_img):\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    canny = cv2.Canny(img, 70, 300)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    \n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    " \n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    " \n",
    "    destination_corners = find_dest(corners)\n",
    " \n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),flags=cv2.INTER_LINEAR)\n",
    "    return Image.fromarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f90e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "      top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ae73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    " \n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    " \n",
    "    return order_points(destination_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eca8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(box,xscale,yscale,xmax,ymax):\n",
    "    box[0]*=1-xscale\n",
    "    box[1]*=1-yscale\n",
    "    box[2]*=1+xscale\n",
    "    box[3]*=1+yscale\n",
    "    if box[2]>xmax:\n",
    "        box[2] = xmax\n",
    "    if box[3]>ymax:\n",
    "        box[3] = ymax\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ba0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_detection(image):\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n",
    "\n",
    "    cropped_img = []\n",
    "    scale = 0.1\n",
    "    all_boxes = []\n",
    "    for i in range(len(results['scores'])):\n",
    "        bounding_box = scaler(results['boxes'][i].tolist(),scale,scale,width,height)\n",
    "        all_boxes.append(bounding_box)\n",
    "        cropped_img.append(image.crop(bounding_box))\n",
    "    \n",
    "    for i in all_boxes:\n",
    "        mask_height = int(i[3] - i[1])\n",
    "        mask_width = int(i[2] - i[0])\n",
    "        square = np.full((mask_height, mask_width),255)\n",
    "        square_img = Image.fromarray(square.astype(np.uint8))\n",
    "        image.paste(square_img,(int(i[0]),int(i[1])))\n",
    "        \n",
    "    return cropped_img,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6310a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_structure_detection(image):\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    target_sizes = [image.size[::-1]]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    output = {\"headers\":[],\"row_data\":[]}\n",
    "    y_scale = 0.03\n",
    "    \n",
    "    #labels == 1 is col_data, 2 is row_data, 3 is col_header_data, 4 is row_header_data\n",
    "    threads = []\n",
    "    result = ThreadSafeList()\n",
    "    for i in range(len(results['boxes'])):\n",
    "        if results['labels'][i] == 4:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_header_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_header_img)\n",
    "            result_header = ocr_model.ocr(np_img)\n",
    "            for i in result_header[0]:\n",
    "                output[\"headers\"].append(i[1][0])\n",
    "        elif results['labels'][i] == 2:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_img)\n",
    "            threads.append(Thread(target=ocr_thread, args=(np_img,result)))\n",
    "    \n",
    "    for i in threads:\n",
    "        i.start()\n",
    "    for i in threads:\n",
    "        i.join()\n",
    "        \n",
    "    for i in range(len(result)):\n",
    "        row_entry = []\n",
    "        for j in result[i][0]:\n",
    "            row_entry.append(j[1][0])\n",
    "        output[\"row_data\"].append(row_entry)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcae60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadSafeList:\n",
    "    def __init__(self):\n",
    "        self._list = list()\n",
    "        self._lock = RLock()\n",
    "    def append(self,data):\n",
    "        with self._lock:\n",
    "            self._list.append(data)\n",
    "    def __getitem__(self, key):\n",
    "        return self._list[key]\n",
    "    def __len__(self):\n",
    "        return len(self._list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51188e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoints(data):\n",
    "    output = {}\n",
    "    for i in data:\n",
    "        x_pos = sum([j[0] for j in i[0]])/4.0\n",
    "        y_pos = sum([j[1] for j in i[0]])/4.0\n",
    "        output[(x_pos,y_pos)] = i[1][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04474783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_table(result):\n",
    "    horizontal_org = {}\n",
    "    horizontal_unorg = {}\n",
    "    vertical_org = {}\n",
    "    vertical_unorg = {}\n",
    "    \n",
    "    midpoints = get_midpoints(result[0])\n",
    "\n",
    "    for i in result[0]:\n",
    "        hori_ls = []\n",
    "        verti_ls = []\n",
    "        if not any(j in i[1][0] for j in '1234567890'):\n",
    "            for k,v in midpoints.items():\n",
    "                max_x = max([n[0] for n in i[0]])\n",
    "                max_y = max([n[1] for n in i[0]])\n",
    "                min_x = min([n[0] for n in i[0]])\n",
    "                min_y = min([n[1] for n in i[0]])\n",
    "\n",
    "                if min_y<k[1]<max_y and v != i[1][0]:\n",
    "                    hori_ls.append((k[0]-i[0][0][0],v))\n",
    "                if min_x<k[0]<max_x and v != i[1][0]:\n",
    "                    verti_ls.append((k[1]-i[0][0][1],v))\n",
    "        if len(hori_ls):\n",
    "            min_val = min([n[0] if n[0]>0 else 100000 for n in hori_ls])\n",
    "            for j in hori_ls:\n",
    "                if j[0] == min_val and min_val>0:\n",
    "                    if any(k in j[1] for k in '1234567890'):\n",
    "                        horizontal_org[i[1][0]] = j[1]\n",
    "                    horizontal_unorg[i[1][0]] = j[1]\n",
    "\n",
    "        if len(verti_ls):\n",
    "            min_val = min([n[0] if n[0]>0 else 100000 for n in verti_ls])\n",
    "            for j in verti_ls:\n",
    "                if j[0] == min_val and min_val>0:\n",
    "                    if any(k in j[1] for k in '1234567890'):\n",
    "                        vertical_org[i[1][0]] = j[1]\n",
    "                    vertical_unorg[i[1][0]] = j[1]\n",
    "\n",
    "    if len(vertical_org)>len(horizontal_org):\n",
    "        return vertical_unorg\n",
    "    else:\n",
    "        return horizontal_unorg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc89180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_no_temp(image,edge_detect=False):\n",
    "    if edge_detect:\n",
    "        #Peform edge detection\n",
    "        img = cv2.cvtColor(np.array(image), cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        image = scan(img,orig_img)\n",
    "        \n",
    "    #Search for table\n",
    "    table,image_no_table = table_detection(image)\n",
    "    \n",
    "    #Extract unorganized data\n",
    "    unorganized_data = np.asarray(image_no_table)\n",
    "    result = ocr_model.ocr(unorganized_data)\n",
    "    extracted_data = organize_table(result)\n",
    "    extracted_data[\"Table_Data\"] = {\"headers\":[],\"row_data\":[],}\n",
    "    \n",
    "    #Extract Table Data\n",
    "    table_output = []\n",
    "    for i in table:\n",
    "        table_output.append(table_structure_detection(i))\n",
    "    \n",
    "    #Get possible header info\n",
    "    for n in range(len(table_output)):\n",
    "        if len(table_output[n][\"headers\"]) == 0:\n",
    "            for i in table_output[n][\"row_data\"]:\n",
    "                data_str = (\",\").join(i)\n",
    "                if not any(j in data_str for j in '1234567890'):\n",
    "                    table_output[n][\"headers\"].append(i)\n",
    "                    table_output[n][\"row_data\"].remove(i)\n",
    "\n",
    "    #Join Data\n",
    "    for n in range(len(table_output)):\n",
    "        extracted_data[\"Table_Data\"][\"headers\"].append(table_output[n][\"headers\"])\n",
    "        extracted_data[\"Table_Data\"][\"row_data\"].append(table_output[n][\"row_data\"])\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f98cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/17 06:43:59] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:44:32] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-61 (ocr_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2637/370562754.py\", line 2, in ocr_thread\n",
      "Exception in thread Thread-71 (ocr_thread):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/paddleocr.py\", line 555, in ocr\n",
      "        self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "dt_boxes, rec_res, _ = self.__call__(img, cls)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/tools/infer/predict_system.py\", line 95, in __call__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2637/370562754.py\", line 2, in ocr_thread\n",
      "    rec_res, elapse = self.text_recognizer(img_crop_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/tools/infer/predict_rec.py\", line 622, in __call__\n",
      "    rec_res[indices[beg_img_no + rno]] = rec_result[rno]\n",
      "IndexError: index 10 is out of bounds for axis 0 with size 10\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/paddleocr.py\", line 555, in ocr\n",
      "    dt_boxes, rec_res, _ = self.__call__(img, cls)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/tools/infer/predict_system.py\", line 95, in __call__\n",
      "    rec_res, elapse = self.text_recognizer(img_crop_list)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/paddleocr/tools/infer/predict_rec.py\", line 622, in __call__\n",
      "    rec_res[indices[beg_img_no + rno]] = rec_result[rno]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 9\n"
     ]
    }
   ],
   "source": [
    "img_path = \"../data/Invoice/CamScanner 06-20-2023 11.20_115.jpg\"\n",
    "data = run_ocr_no_temp(img_path,edge_detect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71bbf1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GUO RUI CHENG PTE LTD': 'Co.REG. NO: 201528808M GST REG. NO: 201528808M',\n",
       " 'EMAIL: grctrading@singnet.com.sg': 'TEL: 6779 5738 FAX: 6779 5581',\n",
       " 'REVERSHINEV': 'ow',\n",
       " 'Goi': 'All',\n",
       " 'All': 'Re',\n",
       " 'ow': \"CUSTOMER'S SIGNATURE & CHOP\",\n",
       " 'Table_Data': {'headers': [[['UNIT PRICE', 'AMOUNT', 'PARTICULABS']]],\n",
       "  'row_data': [[['BLOCK 103 YISHUN RING ROAD', 'z1# DO No'],\n",
       "    ['KIM ENG MINI SUPERMARKET', 'Invoice No#', ':15/034573'],\n",
       "    ['1EL:6/53660817', 'Page'],\n",
       "    ['SINGAPORE 760703',\n",
       "     '1t #k FR 3',\n",
       "     'Terms',\n",
       "     '30 Days',\n",
       "     '..',\n",
       "     'TEL : 67536888 FAX: 67578108'],\n",
       "    ['3s91KmIm CX', 'Date', ':27/05/2020'],\n",
       "    ['GUAINTBY',\n",
       "     '$32.70',\n",
       "     '$32.70',\n",
       "     '2P GULA MELACCA 500G X 20',\n",
       "     '2P # 500G X 20 (3)'],\n",
       "    ['MAUNGGREEN PEAS 397G',\n",
       "     '0.0',\n",
       "     'MIUI 190 LUNCHEON MEAT',\n",
       "     '$15.00',\n",
       "     '$30.00',\n",
       "     '190G'],\n",
       "    ['L', '$7.00', '$7.00', 'DRIED DRAWING', '422.00'],\n",
       "    ['L', '$7.00', '$7.00', 'ASAM KEPING', 'EI', 'DRIED DRAWING', '422.00'],\n",
       "    ['24X35G 3KfiB34',\n",
       "     'KICAP MANIS BIG 12X645ML 1',\n",
       "     '$37.00',\n",
       "     '$37.00',\n",
       "     '12X645ML 3',\n",
       "     'ASAM KEPING',\n",
       "     '$7.00',\n",
       "     '$7.00'],\n",
       "    ['XFXg 200GM',\n",
       "     'KERISIK KELAPAASLI 24X35GM',\n",
       "     '$7.00',\n",
       "     '$7.00',\n",
       "     '24X35G K4',\n",
       "     'KICAP MANIS BIG 12X645ML',\n",
       "     '$37.00',\n",
       "     '$37.00'],\n",
       "    ['AHTI-',\n",
       "     '(BIG)',\n",
       "     '$75.00',\n",
       "     '$150.00',\n",
       "     '24X425G AYAM TALL ETUTAN',\n",
       "     '24X425G XX>J',\n",
       "     'SARDINES (BIG)',\n",
       "     't1050'],\n",
       "    ['XI4UG PUL F)',\n",
       "     'KENTURKY FLOUR 200GMW',\n",
       "     'FXg 200GM',\n",
       "     'KERISIK KELAPAASLI 24X35GM'],\n",
       "    ['12X770G 3t/ (5-t64', 'SAUCE', '0.00', '$8.00', 'M1U1S0L'],\n",
       "    ['3A 3KC 180GMX12',\n",
       "     '180GMX12',\n",
       "     '$30.00',\n",
       "     '$30.00',\n",
       "     '24X425G AYAM BAKED BEANS',\n",
       "     '24X425G X@+',\n",
       "     '(BIG)'],\n",
       "    ['L1 JRF',\n",
       "     '$16.00',\n",
       "     '$16.00',\n",
       "     '25X140G PULI (MEDIUM)',\n",
       "     '1',\n",
       "     '25X140G PULI ()',\n",
       "     'KENTURKY FLOUR 20OGM',\n",
       "     '$6.00',\n",
       "     '$6.00'],\n",
       "    ['24X425G AYAM TALI',\n",
       "     '24X425G XX>T',\n",
       "     '12X770G 3t/ (5-t64',\n",
       "     '125G BABA *$t*',\n",
       "     'BABA 125G CHILLI POWDER',\n",
       "     'M1U1S0L'],\n",
       "    ['125G BABA RX*',\n",
       "     'KENTURKY FLOUR 20OGM',\n",
       "     '25X140G PULI ()',\n",
       "     'BABA 125G KUNYIT POWDER',\n",
       "     '25X140G PULI (MEDIUM)',\n",
       "     '125G BABA '],\n",
       "    ['SARDINES (BIG)',\n",
       "     '$1.05',\n",
       "     '$10.50',\n",
       "     'BABA 125G CHILLI POWDER',\n",
       "     '10',\n",
       "     'F',\n",
       "     '125G BABA **',\n",
       "     '$10.00'],\n",
       "    ['$1.15',\n",
       "     '$11.50',\n",
       "     'SWALLOW BRAND BEE HOON',\n",
       "     '$16.00',\n",
       "     '$16.00',\n",
       "     '25X140GPULL(MEDIUM)'],\n",
       "    ['$1.00',\n",
       "     '$10.00',\n",
       "     '25X140GPULL(MEDIUM)',\n",
       "     '10',\n",
       "     'SWALLOW BRAND BEE HOON',\n",
       "     '$1.15',\n",
       "     '$11.50.',\n",
       "     '$16.00'],\n",
       "    ['E) SER',\n",
       "     'DRIED PRAWNS',\n",
       "     '$22.00',\n",
       "     '$22.00',\n",
       "     'KG',\n",
       "     '4T#F>K',\n",
       "     'TOTAL',\n",
       "     'LKK PANDA 12X770G OYSTER',\n",
       "     '$42.00',\n",
       "     '$42.00',\n",
       "     'fJ'],\n",
       "    ['KG',\n",
       "     '4T+T>K',\n",
       "     'LKK PANDA 12X770G OYSTER',\n",
       "     '$42.00',\n",
       "     '$42.00',\n",
       "     'fJ',\n",
       "     '12X770G (i',\n",
       "     'SAUCE',\n",
       "     'MALING GREEN PEAS 397G',\n",
       "     '$8.00',\n",
       "     '$8.00',\n",
       "     'W++#']]]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00972e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
