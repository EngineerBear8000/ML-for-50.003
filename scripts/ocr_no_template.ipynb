{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8567382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from threading import Thread\n",
    "from threading import RLock\n",
    "ocr_model = PaddleOCR(lang='en',use_angle_cls=False,show_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfbbb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(img,orig_img):\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    canny = cv2.Canny(img, 70, 300)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    \n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    " \n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    " \n",
    "    destination_corners = find_dest(corners)\n",
    " \n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),flags=cv2.INTER_LINEAR)\n",
    "    return Image.fromarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f90e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "      top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ae73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    " \n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    " \n",
    "    return order_points(destination_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eca8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(box,xscale,yscale,xmax,ymax):\n",
    "    box[0]*=1-xscale\n",
    "    box[1]*=1-yscale\n",
    "    box[2]*=1+xscale\n",
    "    box[3]*=1+yscale\n",
    "    if box[2]>xmax:\n",
    "        box[2] = xmax\n",
    "    if box[3]>ymax:\n",
    "        box[3] = ymax\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ba0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_detection(image):\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n",
    "\n",
    "    cropped_img = []\n",
    "    scale = 0.1\n",
    "    all_boxes = []\n",
    "    for i in range(len(results['scores'])):\n",
    "        bounding_box = scaler(results['boxes'][i].tolist(),scale,scale,width,height)\n",
    "        all_boxes.append(bounding_box)\n",
    "        cropped_img.append(image.crop(bounding_box))\n",
    "    \n",
    "    for i in all_boxes:\n",
    "        mask_height = int(i[3] - i[1])\n",
    "        mask_width = int(i[2] - i[0])\n",
    "        square = np.full((mask_height, mask_width),255)\n",
    "        square_img = Image.fromarray(square.astype(np.uint8))\n",
    "        image.paste(square_img,(int(i[0]),int(i[1])))\n",
    "        \n",
    "    return cropped_img,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6310a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_structure_detection(image):\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    target_sizes = [image.size[::-1]]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    output = {\"headers\":[],\"row_data\":[]}\n",
    "    y_scale = 0.03\n",
    "    \n",
    "    #labels == 1 is col_data, 2 is row_data, 3 is col_header_data, 4 is row_header_data\n",
    "    threads = []\n",
    "    result = ThreadSafeList()\n",
    "    for i in range(len(results['boxes'])):\n",
    "        if results['labels'][i] == 4:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_header_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_header_img)\n",
    "            result_header = ocr_model.ocr(np_img)\n",
    "            for i in result_header[0]:\n",
    "                output[\"headers\"].append(i[1][0])\n",
    "        elif results['labels'][i] == 2:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_img)\n",
    "            threads.append(Thread(target=ocr_thread, args=(np_img,result)))\n",
    "    \n",
    "    for i in threads:\n",
    "        i.start()\n",
    "    for i in threads:\n",
    "        i.join()\n",
    "        \n",
    "    for i in range(len(result)):\n",
    "        row_entry = []\n",
    "        for j in result[i][0]:\n",
    "            row_entry.append(j[1][0])\n",
    "        output[\"row_data\"].append(row_entry)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740dda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadSafeList:\n",
    "    def __init__(self):\n",
    "        self._list = list()\n",
    "        self._lock = RLock()\n",
    "    def append(self,data):\n",
    "        with self._lock:\n",
    "            self._list.append(data)\n",
    "    def __getitem__(self, key):\n",
    "        return self._list[key]\n",
    "    def __len__(self):\n",
    "        return len(self._list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcae60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_thread(np_img,result):\n",
    "    data = ocr_model.ocr(np_img)\n",
    "    result.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51188e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoints(data):\n",
    "    output = {}\n",
    "    for i in data:\n",
    "        x_pos = sum([j[0] for j in i[0]])/4.0\n",
    "        y_pos = sum([j[1] for j in i[0]])/4.0\n",
    "        output[(x_pos,y_pos)] = i[1][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04474783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_table(result):\n",
    "    horizontal_org = {}\n",
    "    horizontal_unorg = {}\n",
    "    vertical_org = {}\n",
    "    vertical_unorg = {}\n",
    "    \n",
    "    midpoints = get_midpoints(result[0])\n",
    "\n",
    "    for i in result[0]:\n",
    "        hori_ls = []\n",
    "        verti_ls = []\n",
    "        if not any(j in i[1][0] for j in '1234567890'):\n",
    "            for k,v in midpoints.items():\n",
    "                max_x = max([n[0] for n in i[0]])\n",
    "                max_y = max([n[1] for n in i[0]])\n",
    "                min_x = min([n[0] for n in i[0]])\n",
    "                min_y = min([n[1] for n in i[0]])\n",
    "\n",
    "                if min_y<k[1]<max_y and v != i[1][0]:\n",
    "                    hori_ls.append((k[0]-i[0][0][0],v))\n",
    "                if min_x<k[0]<max_x and v != i[1][0]:\n",
    "                    verti_ls.append((k[1]-i[0][0][1],v))\n",
    "        if len(hori_ls):\n",
    "            min_val = min([n[0] if n[0]>0 else 100000 for n in hori_ls])\n",
    "            for j in hori_ls:\n",
    "                if j[0] == min_val and min_val>0:\n",
    "                    if any(k in j[1] for k in '1234567890'):\n",
    "                        horizontal_org[i[1][0]] = j[1]\n",
    "                    horizontal_unorg[i[1][0]] = j[1]\n",
    "\n",
    "        if len(verti_ls):\n",
    "            min_val = min([n[0] if n[0]>0 else 100000 for n in verti_ls])\n",
    "            for j in verti_ls:\n",
    "                if j[0] == min_val and min_val>0:\n",
    "                    if any(k in j[1] for k in '1234567890'):\n",
    "                        vertical_org[i[1][0]] = j[1]\n",
    "                    vertical_unorg[i[1][0]] = j[1]\n",
    "\n",
    "    if len(vertical_org)>len(horizontal_org):\n",
    "        return vertical_unorg\n",
    "    else:\n",
    "        return horizontal_unorg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc89180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_no_temp(image,edge_detect=False):\n",
    "    if edge_detect:\n",
    "        #Peform edge detection\n",
    "        img = cv2.cvtColor(np.array(image), cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        image = scan(img,orig_img)\n",
    "        \n",
    "    #Search for table\n",
    "    table,image_no_table = table_detection(image)\n",
    "    \n",
    "    #Extract unorganized data\n",
    "    unorganized_data = np.asarray(image_no_table)\n",
    "    result = ocr_model.ocr(unorganized_data)\n",
    "    extracted_data = organize_table(result)\n",
    "    extracted_data[\"Table_Data\"] = {\"headers\":[],\"row_data\":[],}\n",
    "    \n",
    "    #Extract Table Data\n",
    "    table_output = []\n",
    "    for i in table:\n",
    "        table_output.append(table_structure_detection(i))\n",
    "    \n",
    "    #Get possible header info\n",
    "    for n in range(len(table_output)):\n",
    "        if len(table_output[n][\"headers\"]) == 0:\n",
    "            for i in table_output[n][\"row_data\"]:\n",
    "                data_str = (\",\").join(i)\n",
    "                if not any(j in data_str for j in '1234567890'):\n",
    "                    table_output[n][\"headers\"].append(i)\n",
    "                    table_output[n][\"row_data\"].remove(i)\n",
    "\n",
    "    #Join Data\n",
    "    for n in range(len(table_output)):\n",
    "        extracted_data[\"Table_Data\"][\"headers\"].append(table_output[n][\"headers\"])\n",
    "        extracted_data[\"Table_Data\"][\"row_data\"].append(table_output[n][\"row_data\"])\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f98cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/18 01:15:56] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:16:05] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TemplateLAB': 'COMMERCIAL',\n",
       " 'COMMERCIAL': 'INVOICE',\n",
       " 'INVOICE': 'International Sales Operations',\n",
       " 'COMPANY NAME': 'SLOGAN GOES HERE',\n",
       " 'International Sales Operations': 'INVOICE NUMBER',\n",
       " 'FORWARDING AGENT': 'DHL',\n",
       " 'DATE': '14/08/2023',\n",
       " 'INVOICE NUMBER': 'F1000876/23',\n",
       " 'DHL': 'SOLD BY',\n",
       " 'TRACKING NUMBER': '55888800000998700',\n",
       " 'PAID BY': 'CREDIT CARD',\n",
       " 'ORDER ID': ' X001525',\n",
       " 'CREDIT CARD': 'BILL TO',\n",
       " 'SOLD BY': 'LOCAL STORE',\n",
       " 'BILL TO': '100 Mighty Bay',\n",
       " 'LOCAL STORE': '255 Commercial Street',\n",
       " 'IMPORTING COMPANY': '100 Mighty Bay',\n",
       " 'info@localstore.com': 'EORI: PT100003456566',\n",
       " ' info@localstore.com': 'EORI: PT100003456566',\n",
       " 'Table_Data': {'headers': [[['PRODUCT',\n",
       "     'HS CODE',\n",
       "     'UNITS',\n",
       "     'UNIT PRICE',\n",
       "     'TOTAL']]],\n",
       "  'row_data': [[['Reason for export: SALE', 'Shipping Charges', '$100.00'],\n",
       "    ['Incoterms: DAP', 'Insurance', '$0.00', 'Description of the goods'],\n",
       "    ['Pole with bracket',\n",
       "     '88565.2545',\n",
       "     '1',\n",
       "     '$85.00',\n",
       "     '$85.00',\n",
       "     'Country of origin: US'],\n",
       "    ['$485.00', 'Sub Total', 'Insurance:NOT INCLUDED'],\n",
       "    ['Insurance:NOT INCLUDED', 'Sub Total', '$485.00'],\n",
       "    ['Description of the goods',\n",
       "     'Sales Tax (VAT)',\n",
       "     '(number of packages, units, weight, etc.):',\n",
       "     '$117.00',\n",
       "     'Pallet 1200x800x1500mm (15.2kg)1pc'],\n",
       "    ['Pole with bracket',\n",
       "     '88565.2545',\n",
       "     '1',\n",
       "     '$85.00',\n",
       "     '$85.00',\n",
       "     'Country of origin: US'],\n",
       "    ['Conveyor Belt 25 \"',\n",
       "     '88565.2252',\n",
       "     '2',\n",
       "     '$200.00',\n",
       "     '$400.00',\n",
       "     'Country of origin: US'],\n",
       "    ['Pole with bracket',\n",
       "     '88505.2545',\n",
       "     '1',\n",
       "     '$85.00',\n",
       "     '$85.00',\n",
       "     'country of origin: os'],\n",
       "    ['Pallet 1200x800x1500mm(15.2kg)1pc',\n",
       "     'Total',\n",
       "     '$702.00',\n",
       "     'Carton Box150x200x100mm(15.2kg) 3pcs']]]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"../data/invoice_sample.jpg\"\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "run_ocr_no_temp(image,edge_detect=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
