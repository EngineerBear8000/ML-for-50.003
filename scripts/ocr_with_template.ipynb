{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4200c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import numpy as np\n",
    "ocr_model = PaddleOCR(lang='en',use_angle_cls=False,show_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoints(data):\n",
    "    output = {}\n",
    "    for i in data:\n",
    "        x_pos = sum([j[0] for j in i[0]])/4.0\n",
    "        y_pos = sum([j[1] for j in i[0]])/4.0\n",
    "        output[(x_pos,y_pos)] = i[1][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0d9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requested_data(template_data_loc,data):\n",
    "    data_loc = get_midpoints(data)\n",
    "    output = {}\n",
    "    for k,v in data_loc.items():\n",
    "        for i,j in template_data_loc.items():\n",
    "            x_min,x_max = j[0][0],j[1][0]\n",
    "            y_min,y_max = j[0][1],j[2][1]\n",
    "            if (x_min<k[0]<x_max and y_min<k[1]<y_max):\n",
    "                if i in output.keys():\n",
    "                    output[i] = output[i] + \" \" + v\n",
    "                else:\n",
    "                    output[i] = v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ede61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(box,xscale,yscale,xmax,ymax):\n",
    "    box[0]*=1-xscale\n",
    "    box[1]*=1-yscale\n",
    "    box[2]*=1+xscale\n",
    "    box[3]*=1+yscale\n",
    "    if box[2]>xmax:\n",
    "        box[2] = xmax\n",
    "    if box[3]>ymax:\n",
    "        box[3] = ymax\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052e13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_structure_detection(image):\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    target_sizes = [image.size[::-1]]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.8, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    output = {\"headers\":[],\"row_data\":[]}\n",
    "    y_scale = 0.03\n",
    "    \n",
    "    #labels == 1 is col_data, 2 is row_data, 3 is col_header_data, 4 is row_header_data\n",
    "    for i in range(len(results['boxes'])):\n",
    "        if results['labels'][i] == 4:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_header_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_header_img)\n",
    "            result = ocr_model.ocr(np_img)\n",
    "            for i in result[0]:\n",
    "                output[\"headers\"].append(i[1][0])\n",
    "        elif results['labels'][i] == 2:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_img)\n",
    "            result = ocr_model.ocr(np_img)\n",
    "            row_data_entry = []\n",
    "            for i in result[0]:\n",
    "                row_data_entry.append(i[1][0])\n",
    "            output[\"row_data\"].append(row_data_entry)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c0875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/12 04:44:58] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/12 04:45:17] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/12 04:45:18] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/12 04:45:20] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/12 04:45:21] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/12 04:45:22] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    }
   ],
   "source": [
    "img_path = \"../data/invoice_sample.jpg\"\n",
    "template_data_loc = {\"Invoice Number\":[[967.0, 365.0], [1074.0, 365.0], [1074.0, 386.0], [967.0, 386.0]],\n",
    "                     \"Date\":[[781.0, 365.0], [876.0, 365.0], [876.0, 386.0], [781.0, 386.0]],\n",
    "                    \"Address\":[[89.0, 605.0], [269.0, 605.0], [269.0, 661.0], [89.0, 661.0]],\n",
    "                    \"Table_Data\":[[85.0, 855.0], [1160.0, 855.0], [1160.0, 1310.0], [85.0,1310.0]]}\n",
    "table_box = (template_data_loc[\"Table_Data\"][0][0],template_data_loc[\"Table_Data\"][0][1],\n",
    "             template_data_loc[\"Table_Data\"][1][0],template_data_loc[\"Table_Data\"][2][1],)\n",
    "\n",
    "#Peform edge detection and image distortion if required\n",
    "\n",
    "#Extract data requested from template \n",
    "data = ocr_model.ocr(img_path)[0]\n",
    "extracted_data = extract_requested_data(template_data_loc,data)\n",
    "\n",
    "#Extract Table Data\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "table = image.crop(table_box)\n",
    "table_output = table_structure_detection(table)\n",
    "\n",
    "#Join Data\n",
    "extracted_data[\"Table_Data\"] = table_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705134ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '14/08/2023',\n",
       " 'Invoice Number': 'F1000876/23',\n",
       " 'Address': '255 Commercial Street 25880 New York, US',\n",
       " 'Table_Data': {'headers': [],\n",
       "  'row_data': [['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: US'],\n",
       "   ['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: US'],\n",
       "   ['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: US'],\n",
       "   ['Conveyor Belt 25 \"',\n",
       "    '88565.2252',\n",
       "    '2',\n",
       "    '$200.00',\n",
       "    '$400.00',\n",
       "    'Country of origin: US'],\n",
       "   ['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: US']]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09242342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
