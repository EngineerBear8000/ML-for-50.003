{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4200c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from threading import Thread\n",
    "from threading import RLock\n",
    "ocr_model = PaddleOCR(lang='en',use_angle_cls=False,show_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeb6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(img,orig_img):\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    canny = cv2.Canny(img, 70, 300)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    \n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    " \n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    " \n",
    "    destination_corners = find_dest(corners)\n",
    " \n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),flags=cv2.INTER_LINEAR)\n",
    "    return Image.fromarray(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cd8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "      top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff56863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    " \n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    " \n",
    "    return order_points(destination_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db1ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoints(data):\n",
    "    output = {}\n",
    "    for i in data:\n",
    "        x_pos = sum([j[0] for j in i[0]])/4.0\n",
    "        y_pos = sum([j[1] for j in i[0]])/4.0\n",
    "        output[(x_pos,y_pos)] = i[1][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0d9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requested_data(template_data_loc,data):\n",
    "    data_loc = get_midpoints(data)\n",
    "    output = {}\n",
    "    for k,v in data_loc.items():\n",
    "        for i,j in template_data_loc.items():\n",
    "            x_min,x_max = j[0][0],j[1][0]\n",
    "            y_min,y_max = j[0][1],j[2][1]\n",
    "            if (x_min<k[0]<x_max and y_min<k[1]<y_max):\n",
    "                if i in output.keys():\n",
    "                    output[i] = output[i] + \" \" + v\n",
    "                else:\n",
    "                    output[i] = v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ede61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(box,xscale,yscale,xmax,ymax):\n",
    "    box[0]*=1-xscale\n",
    "    box[1]*=1-yscale\n",
    "    box[2]*=1+xscale\n",
    "    box[3]*=1+yscale\n",
    "    if box[2]>xmax:\n",
    "        box[2] = xmax\n",
    "    if box[3]>ymax:\n",
    "        box[3] = ymax\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca848b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadSafeList:\n",
    "    def __init__(self):\n",
    "        self._list = list()\n",
    "        self._lock = RLock()\n",
    "    def append(self,data):\n",
    "        with self._lock:\n",
    "            self._list.append(data)\n",
    "    def __getitem__(self, key):\n",
    "        return self._list[key]\n",
    "    def __len__(self):\n",
    "        return len(self._list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1008bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_thread(np_img,result):\n",
    "    data = ocr_model.ocr(np_img)\n",
    "    result.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052e13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_structure_detection(image):\n",
    "    global lock\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    target_sizes = [image.size[::-1]]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    output = {\"headers\":[],\"row_data\":[]}\n",
    "    y_scale = 0.03\n",
    "    \n",
    "    threads = []\n",
    "    result = ThreadSafeList()\n",
    "    for i in range(len(results['boxes'])):\n",
    "        if results['labels'][i] == 4:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_header_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_header_img)\n",
    "            header_result = ocr_model.ocr(np_img)\n",
    "            for i in header_result[0]:\n",
    "                output[\"headers\"].append(i[1][0])\n",
    "        elif results['labels'][i] == 2:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_img)\n",
    "            threads.append(Thread(target=ocr_thread, args=(np_img,result)))\n",
    "    for i in threads:\n",
    "        i.start()\n",
    "    for i in threads:\n",
    "        i.join()\n",
    "    for i in range(len(result)):\n",
    "        row_entry = []\n",
    "        for j in result[i][0]:\n",
    "            row_entry.append(j[1][0])\n",
    "        output[\"row_data\"].append(row_entry)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a08780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_with_temp(image,template_data_loc,template_size,edge_detect=False):\n",
    "    table_box = (template_data_loc[\"Table_Data\"][0][0],template_data_loc[\"Table_Data\"][0][1],\n",
    "             template_data_loc[\"Table_Data\"][1][0],template_data_loc[\"Table_Data\"][2][1])\n",
    "    \n",
    "    if edge_detect:\n",
    "        #Peform edge detection\n",
    "        img = cv2.cvtColor(np.array(image), cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        image = scan(img,orig_img)\n",
    "\n",
    "    #Perform image resizing\n",
    "    image = image.resize(template_size)\n",
    "    \n",
    "    #Extract data requested from template \n",
    "    template_data = np.asarray(image)\n",
    "    data = ocr_model.ocr(template_data)[0]\n",
    "    extracted_data = extract_requested_data(template_data_loc,data)\n",
    "    \n",
    "    #Extract Table Data\n",
    "    table = image.crop(table_box)\n",
    "    table_output = table_structure_detection(table)\n",
    "\n",
    "    #Get possible header info\n",
    "    if len(table_output[\"headers\"]) == 0:\n",
    "        for i in table_output[\"row_data\"]:\n",
    "            data_str = (\",\").join(i)\n",
    "            if not any(j in data_str for j in '1234567890'):\n",
    "                table_output[\"headers\"].append(i)\n",
    "                table_output[\"row_data\"].remove(i)\n",
    "\n",
    "    #Join Data\n",
    "    extracted_data[\"Table_Data\"] = table_output\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c0875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/18 01:14:53] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/18 01:15:10] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Date': '14/08/2023',\n",
       " 'Invoice Number': 'F1000876/23',\n",
       " 'Address': '255 Commercial Street 25880 New York, US',\n",
       " 'Table_Data': {'headers': [['PRODUCT',\n",
       "    'HS CODE',\n",
       "    'UNITS',\n",
       "    'UNIT PRICE',\n",
       "    'TOTAL']],\n",
       "  'row_data': [['Country of origin: US',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Pole with bracket'],\n",
       "   ['Polewitn bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: Us'],\n",
       "   ['Polewitn bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: Us'],\n",
       "   ['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: US'],\n",
       "   ['Pole with bracket',\n",
       "    '88565.2545',\n",
       "    '1',\n",
       "    '$85.00',\n",
       "    '$85.00',\n",
       "    'Country of origin: Us']]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"../data/invoice_sample.jpg\"\n",
    "template_data_loc = {\"Invoice Number\":[[967.0, 365.0], [1074.0, 365.0], [1074.0, 386.0], [967.0, 386.0]],\n",
    "                     \"Date\":[[781.0, 365.0], [876.0, 365.0], [876.0, 386.0], [781.0, 386.0]],\n",
    "                    \"Address\":[[89.0, 605.0], [269.0, 605.0], [269.0, 661.0], [89.0, 661.0]],\n",
    "                    \"Table_Data\":[[85.0, 840.0], [1160.0, 840.0], [1160.0, 1310.0], [85.0,1310.0]]}\n",
    "template_size = (1240, 1754)\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "run_ocr_with_temp(image,template_data_loc,template_size,edge_detect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cb737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
