{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4200c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /home/jovyan/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 4.00M/4.00M [00:05<00:00, 760kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar to /home/jovyan/.paddleocr/whl/rec/en/en_PP-OCRv3_rec_infer/en_PP-OCRv3_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 9.96M/9.96M [00:08<00:00, 1.22MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /home/jovyan/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2.19M/2.19M [00:00<00:00, 2.87MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import threading\n",
    "ocr_model = PaddleOCR(lang='en',use_angle_cls=False,show_log=False)\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adeb6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(img,orig_img):\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    canny = cv2.Canny(img, 70, 300)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    \n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    " \n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    " \n",
    "    destination_corners = find_dest(corners)\n",
    " \n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),flags=cv2.INTER_LINEAR)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cd8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "      top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    " \n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff56863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    " \n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    " \n",
    "    return order_points(destination_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db1ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219c29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midpoints(data):\n",
    "    output = {}\n",
    "    for i in data:\n",
    "        x_pos = sum([j[0] for j in i[0]])/4.0\n",
    "        y_pos = sum([j[1] for j in i[0]])/4.0\n",
    "        output[(x_pos,y_pos)] = i[1][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0d9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_requested_data(template_data_loc,data):\n",
    "    data_loc = get_midpoints(data)\n",
    "    output = {}\n",
    "    for k,v in data_loc.items():\n",
    "        for i,j in template_data_loc.items():\n",
    "            x_min,x_max = j[0][0],j[1][0]\n",
    "            y_min,y_max = j[0][1],j[2][1]\n",
    "            if (x_min<k[0]<x_max and y_min<k[1]<y_max):\n",
    "                if i in output.keys():\n",
    "                    output[i] = output[i] + \" \" + v\n",
    "                else:\n",
    "                    output[i] = v\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ede61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(box,xscale,yscale,xmax,ymax):\n",
    "    box[0]*=1-xscale\n",
    "    box[1]*=1-yscale\n",
    "    box[2]*=1+xscale\n",
    "    box[3]*=1+yscale\n",
    "    if box[2]>xmax:\n",
    "        box[2] = xmax\n",
    "    if box[3]>ymax:\n",
    "        box[3] = ymax\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1008bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_thread(np_img,result,lock):\n",
    "    data = ocr_model.ocr(np_img)\n",
    "    lock.acquire()\n",
    "    result.append(data)\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052e13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_structure_detection(image):\n",
    "    global lock\n",
    "    width, height = image.size\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    target_sizes = [image.size[::-1]]\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "    \n",
    "    output = {\"headers\":[],\"row_data\":[]}\n",
    "    y_scale = 0.03\n",
    "    \n",
    "    threads = []\n",
    "    result = []\n",
    "    for i in range(len(results['boxes'])):\n",
    "        if results['labels'][i] == 4:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_header_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_header_img)\n",
    "            result = ocr_model.ocr(np_img)\n",
    "            for i in result[0]:\n",
    "                output[\"headers\"].append(i[1][0])\n",
    "        elif results['labels'][i] == 2:\n",
    "            bounding_box = scaler(results['boxes'][i].tolist(),1,y_scale,width,height)\n",
    "            row_img = image.crop(bounding_box)\n",
    "            np_img = np.asarray(row_img)\n",
    "            threads.append(threading.Thread(target=ocr_thread, args=(np_img,result,lock)))\n",
    "    for i in threads:\n",
    "        i.start()\n",
    "    for i in threads:\n",
    "        i.join()\n",
    "    for i in result:\n",
    "        row_entry = []\n",
    "        for j in i[0]:\n",
    "            row_entry.append(j[1][0])\n",
    "        output[\"row_data\"].append(row_entry)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a08780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_with_temp(img_path,template_data_loc,template_size,edge_detect=False):\n",
    "    table_box = (template_data_loc[\"Table_Data\"][0][0],template_data_loc[\"Table_Data\"][0][1],\n",
    "             template_data_loc[\"Table_Data\"][1][0],template_data_loc[\"Table_Data\"][2][1])\n",
    "    \n",
    "    if edge_detect:\n",
    "        #Peform edge detection\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        orig_img = cv2.imread(img_path)\n",
    "        output = scan(img,orig_img)\n",
    "        show(output)\n",
    "        img_path = img_path[:-4]+ \"_cropped\"+img_path[-4:]\n",
    "        cv2.imwrite(img_path,output)\n",
    "\n",
    "    #Perform image resizing\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = image.resize(template_size)\n",
    "    \n",
    "    #Extract data requested from template \n",
    "    template_data = np.asarray(image)\n",
    "    data = ocr_model.ocr(template_data)[0]\n",
    "    extracted_data = extract_requested_data(template_data_loc,data)\n",
    "    \n",
    "    #Extract Table Data\n",
    "    table = image.crop(table_box)\n",
    "    table_output = table_structure_detection(table)\n",
    "\n",
    "    #Get possible header info\n",
    "    if len(table_output[\"headers\"]) == 0:\n",
    "        for i in table_output[\"row_data\"]:\n",
    "            data_str = (\",\").join(i)\n",
    "            if not any(j in data_str for j in '1234567890'):\n",
    "                table_output[\"headers\"].append(i)\n",
    "                table_output[\"row_data\"].remove(i)\n",
    "\n",
    "    #Join Data\n",
    "    extracted_data[\"Table_Data\"] = table_output\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c0875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/17 06:14:39] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 06:14:47] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Address': '20',\n",
       " 'Table_Data': {'headers': [],\n",
       "  'row_data': [['LKK PANDA 12X770G OYSTEI', '$42.00', '$42.00', '12X770G ('],\n",
       "   ['1LX12 KARA COCOMUT MILK', '$37.85', '1LX12 KARA #3', '$75.70'],\n",
       "   ['1', '24X184G SUNKEE FRIED DAC', '$54.00', '$54.00', '24X184G T', 'FISHO'],\n",
       "   ['MIU CORN BEEF 340G', '1jJ', '340G', '$31.80', '$31.80', 'SAUCE'],\n",
       "   ['SAUCE', '1jJ', 'MIU CORN BEEF 340G', '$31.80', '$31.80', '340G'],\n",
       "   ['24X182GT', '1', '$54.00', '$54.00', '24 MILI FRIED DACE'],\n",
       "   ['1', '25X140GPULI', 'Z5XI40GPUUMEDI', '$10.00', '$16.00']]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"../data/Invoice/CamScanner 06-20-2023 11.20_118.jpg\" #invoice_sample.jpg\n",
    "template_data_loc = {\"Invoice Number\":[[967.0, 365.0], [1074.0, 365.0], [1074.0, 386.0], [967.0, 386.0]],\n",
    "                     \"Date\":[[781.0, 365.0], [876.0, 365.0], [876.0, 386.0], [781.0, 386.0]],\n",
    "                    \"Address\":[[89.0, 605.0], [269.0, 605.0], [269.0, 661.0], [89.0, 661.0]],\n",
    "                    \"Table_Data\":[[85.0, 840.0], [1160.0, 840.0], [1160.0, 1310.0], [85.0,1310.0]]}\n",
    "template_size = (1240, 1754)\n",
    "\n",
    "run_ocr_with_temp(img_path,template_data_loc,template_size,edge_detect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "988cb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/17 08:49:34] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 08:49:41] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 08:49:41] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 08:49:41] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n",
      "[2023/07/17 08:49:41] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Date': ': 22/05/2020 : 15/ 034499',\n",
       " 'Invoice Number': ': 15/ 034499',\n",
       " 'Address': 'BLOCK 103 YISHUN RING ROAD 01-79 SINGAPORE 760703',\n",
       " 'Table_Data': {'headers': [],\n",
       "  'row_data': [[' BELECAN BULAT', '$8.00', '$8.00', '1AY20201'],\n",
       "   ['25X140G PULI (MEDIUM)', '$16.00', '$16.00', '25X140G PULI ()'],\n",
       "   ['1ONTONG ADDA', '28.50', '557.00', 'ADABIXSXK'],\n",
       "   ['200G GRANULATED COCONUT',\n",
       "    '$1.10',\n",
       "    '20',\n",
       "    '200G',\n",
       "    '$22.00',\n",
       "    '2',\n",
       "    'SUGAR R']]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"../data/Invoice/CamScanner 06-20-2023 11.20_118.jpg\" #Top left top right bottom right bottom left\n",
    "template_data_loc = {\"Invoice Number\":[[1382.0, 465.0], [1686.0, 465.0], [1686.0, 517.0], [1382.0, 517.0]],\n",
    "                     \"Date\":[[1388.0, 415.0], [1694.0, 415.0], [1694.0, 474.0], [1388.0, 474.0]],\n",
    "                    \"Address\":[[91.0, 483.0], [564.0, 483.0], [564.0, 603.0], [91.0, 603.0]],\n",
    "                    \"Table_Data\":[[24.0, 716.0], [1744.0, 2004.0], [1744.0, 1310.0], [24.0,2004.0]]}\n",
    "template_size = (1763, 2299)\n",
    "\n",
    "run_ocr_with_temp(img_path,template_data_loc,template_size,edge_detect=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
